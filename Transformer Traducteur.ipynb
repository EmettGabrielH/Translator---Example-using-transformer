{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b75c27-44d6-41eb-b2b1-33b389545c7d",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/translation_transformer.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7503dc7f-f203-4fc8-96d6-0c152431a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math, time\n",
    "import unicodedata, re, random\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "466ab31f-8e25-44e6-8bed-f897bde4e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG_class:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.batch_size = 64         # Batch size = h , 64\n",
    "        self.max_seq_length = 14\n",
    "        self.src_vocab_size = 0\n",
    "        self.tgt_vocab_size = 0\n",
    "        \n",
    "        # Hyperparameters for the Transformer model\n",
    "        self.d_model = 256           # Embedding size for each word, 512\n",
    "        self.num_heads = 8           # Number of attention heads, 8\n",
    "        self.num_layers_encoder = 6  # Number of encoder layers, 6\n",
    "        self.num_layers_decoder = 6  # Number of decoder layers, 6\n",
    "        self.d_feedforward = 1024    # Dimension of the feedforward layer, 2048\n",
    "        self.dropout = 0.1           # Dropout rate to prevent overfitting\n",
    "\n",
    "CONFIG = CONFIG_class()\n",
    "\n",
    "Lang1, Lang2 = \"eng\",\"fra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "450f2f3f-ccf0-478e-a8a5-78a8812e5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token ,START_token, END_token, PADDING_token = 3, 1, 2, 0\n",
    "SOS,START, END, PADDING = \"[SOS]\",\"[START]\", \"[END]\", \"[PADDING]\"\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {PADDING: PADDING_token, START: START_token, END:END_token, SOS: SOS_token}\n",
    "        self.index2word = {SOS_token: SOS, START_token: START, END_token: END, PADDING_token: PADDING}\n",
    "        self.n_words = 4\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = s.lower().strip()\n",
    "    s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return START + \" \" + s.strip() + \" \" + END\n",
    "\n",
    "    \n",
    "def prepareData(lang1, lang2, reverse):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = [pair for pair in pairs if len(pair[0].split(' ')) < CONFIG.max_seq_length and len(pair[1].split(' ')) < CONFIG.max_seq_length ]\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    return indexes\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c2c8e1-c898-41e6-93d7-2826fff3afa5",
   "metadata": {},
   "source": [
    "def get_dataloader(config):\n",
    "    input_lang, output_lang, pairs = prepareData(Lang1, Lang2, False)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, config.max_seq_length), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, config.max_seq_length), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(config.device), torch.LongTensor(target_ids).to(config.device))\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=config.batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9eedb2-f368-4f43-aa8d-a3e70dbc733e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa9961d4-d909-4568-9d6c-db9b43dbbfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiskDataset(Dataset):\n",
    "    def __init__(self, input_file, target_file, length, max_seq_length):\n",
    "        self.input_file = input_file\n",
    "        self.target_file = target_file\n",
    "        self.length = length\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(self.input_file, 'rb') as f_input, open(self.target_file, 'rb') as f_target:\n",
    "            # Calcul de la position du batch à lire\n",
    "            f_input.seek(idx * self.max_seq_length * 4)  # 4 bytes par int32\n",
    "            f_target.seek(idx * self.max_seq_length * 4)\n",
    "\n",
    "            # Lecture des données du fichier\n",
    "            input_data = np.fromfile(f_input, dtype=np.int32, count=self.max_seq_length)\n",
    "            target_data = np.fromfile(f_target, dtype=np.int32, count=self.max_seq_length)\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        return torch.LongTensor(input_data).to(device), torch.LongTensor(target_data).to(device)\n",
    "\n",
    "def save_data_to_disk(input_ids, target_ids, input_file, target_file):\n",
    "    input_ids.tofile(input_file)\n",
    "    target_ids.tofile(target_file)\n",
    "\n",
    "def get_dataloader(config,reverse):\n",
    "    input_lang, output_lang, pairs = prepareData(Lang1, Lang2, reverse)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, config.max_seq_length), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, config.max_seq_length), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    # Sauvegarder les données sur le disque\n",
    "    input_file = 'input_ids.bin'\n",
    "    target_file = 'target_ids.bin'\n",
    "    save_data_to_disk(input_ids, target_ids, input_file, target_file)\n",
    "\n",
    "    # Créer un Dataset personnalisé qui charge les données depuis le disque\n",
    "    train_data = DiskDataset(input_file, target_file, n, config.max_seq_length)\n",
    "    train_dataloader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    return input_lang, output_lang, train_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b564255-c6ee-46d2-a145-8d27bfb582c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 406476 sentence pairs\n",
      "Trimmed to 358902 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 36065\n",
      "eng 25844\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, train_dataloader = get_dataloader(CONFIG, reverse = True)\n",
    "\n",
    "CONFIG.src_vocab_size = input_lang.n_words  # Taille du vocabulaire pour la langue source\n",
    "CONFIG.tgt_vocab_size = output_lang.n_words  # Taille du vocabulaire pour la langue cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ece2b7ea-fae0-4c34-afd2-53475501def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Module that adds positional encoding to the token embedding\n",
    "# to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        \n",
    "        den = torch.exp(-torch.arange(0, config.d_model, 2) * (math.log(10000) / config.d_model))\n",
    "        pos = torch.arange(config.max_seq_length).unsqueeze(1)  # shape: (max_seq_length, 1)\n",
    "        pos_embedding = torch.zeros(config.max_seq_length, config.d_model)\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "\n",
    "        pos_embedding = pos_embedding.unsqueeze(0).repeat(config.batch_size, 1, 1)\n",
    "\n",
    "        # Store the positional embedding in a buffer (a tensor that is not a parameter)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "        \n",
    "        # Define dropout layer to be applied to the embeddings\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        # Add positional encoding to token embeddings and apply dropout\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :token_embedding.size(1)])\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        \n",
    "        # Create an embedding layer that maps each token index to an embedding vector\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.d_model)\n",
    "\n",
    "\n",
    "# Seq2Seq Network using Transformer architecture\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        \n",
    "        # Define the Transformer model with encoder and decoder layers\n",
    "        self.transformer = nn.Transformer(d_model=config.d_model, nhead=config.num_heads, num_encoder_layers=config.num_layers_encoder, \n",
    "                                          num_decoder_layers=config.num_layers_decoder, dim_feedforward=config.d_feedforward, dropout=config.dropout,\n",
    "                                          activation = \"gelu\", norm_first = False, batch_first = True, device = config.device)\n",
    "        \n",
    "        # Linear layer to project the transformer output to the target vocabulary size\n",
    "        self.generator = nn.Linear(config.d_model, config.tgt_vocab_size)\n",
    "        \n",
    "        # Token embedding layers for source and target sequences\n",
    "        self.src_token_emb = TokenEmbedding(config.src_vocab_size, config.d_model)\n",
    "        self.tgt_token_emb = TokenEmbedding(config.tgt_vocab_size, config.d_model)\n",
    "        \n",
    "        # Positional encoding layer to add positional information to embeddings\n",
    "        self.positional_encoding = PositionalEncoding(config)\n",
    "\n",
    "    def forward(self, src, trg, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask):\n",
    "\n",
    "        src_emb = self.positional_encoding(self.src_token_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_token_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        #forward(src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        # Encode the source sequence using the Transformer encoder\n",
    "        return self.transformer.encoder(self.positional_encoding(self.src_token_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        # Decode the target sequence using the Transformer decoder with memory from the encoder\n",
    "        return self.transformer.decoder(self.positional_encoding(self.tgt_token_emb(tgt)), memory, tgt_mask)\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    # Get the length of source and target sequences\n",
    "    src_seq_len, tgt_seq_len = src.shape[1], tgt.shape[1]\n",
    "\n",
    "    # Generate a target mask for self-attention to prevent attending to future tokens\n",
    "    tgt_mask = torch.triu(torch.ones(tgt_seq_len, tgt_seq_len, dtype=torch.bool, device=CONFIG.device), diagonal=1)\n",
    "    \n",
    "    # Create a zero source mask (no masking for self-attention in encoder)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=CONFIG.device).type(torch.bool)\n",
    "\n",
    "    # Create padding masks for the source and target sequences\n",
    "    src_padding_mask, tgt_padding_mask = (src == PADDING_token), (tgt == PADDING_token)\n",
    "    \n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac3934-c761-49a1-ab4d-41b7b7d2df6a",
   "metadata": {},
   "source": [
    "transformer = Seq2SeqTransformer(CONFIG)\n",
    "\n",
    "\n",
    "for parameter in transformer.parameters():\n",
    "    if parameter.dim() > 1: nn.init.xavier_uniform_(parameter)\n",
    "\n",
    "transformer = transformer.to(CONFIG.device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PADDING_token)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "min_loss = float(\"+inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f3b9e64-60fe-4271-84bb-0a957c34ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    def __init__(self, model, input_lang, output_lang, config):\n",
    "        self.model = model\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.config = config\n",
    "        \n",
    "    def save(self, path):\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),  # Enregistrer uniquement les poids du modèle\n",
    "            'input_lang': self.input_lang,\n",
    "            'output_lang': self.output_lang,\n",
    "            'config': self.config\n",
    "        }, path)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        checkpoint = torch.load(path, weights_only=False)\n",
    "        input_lang = checkpoint['input_lang']\n",
    "        output_lang = checkpoint['output_lang']\n",
    "        config = checkpoint['config']\n",
    "        model = Seq2SeqTransformer(config)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model = model.to(config.device)\n",
    "        return cls(model, input_lang, output_lang, config)\n",
    "\n",
    "\n",
    "    def evaluate(self, src_sentence):\n",
    "        self.model.eval()\n",
    "        src = tensorFromSentence(self.input_lang, normalizeString(src_sentence))\n",
    "        num_tokens = src.shape[1]\n",
    "        src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "        \n",
    "        src = src.to(CONFIG.device)\n",
    "        src_mask = src_mask.to(self.config.device)\n",
    "    \n",
    "        memory = self.model.encode(src, src_mask)\n",
    "        ys = torch.ones(1, 1).fill_(START_token).type(torch.long).to(self.config.device)\n",
    "        \n",
    "        for i in range(CONFIG.max_seq_length):\n",
    "            memory = memory.to(self.config.device)\n",
    "            tgt_mask = torch.triu(torch.ones(ys.size(1), ys.size(1), dtype=torch.bool, device=self.config.device), diagonal=1)\n",
    "            out = self.model.decode(ys, memory, tgt_mask)\n",
    "            prob = self.model.generator(out[:, -1])\n",
    "            _, next_word = torch.max(prob, dim=1)\n",
    "            next_word = next_word.item()\n",
    "            ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "            if next_word == END_token:\n",
    "                break\n",
    "                \n",
    "        tgt_tokens = ys.flatten()\n",
    "        return \" \".join([self.output_lang.index2word[token.item()] for token in tgt_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77de0fae-f8c5-4c7c-9857-ef2350abd478",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'translator_model_fra_eng2.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslator_model_fra_eng2.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m loaded_translator \u001b[38;5;241m=\u001b[39m \u001b[43mTranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m transformer \u001b[38;5;241m=\u001b[39m loaded_translator\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m      4\u001b[0m input_lang \u001b[38;5;241m=\u001b[39m loaded_translator\u001b[38;5;241m.\u001b[39minput_lang\n",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m, in \u001b[0;36mTranslator.load\u001b[1;34m(cls, path)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path):\n\u001b[1;32m---> 18\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     input_lang \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_lang\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     20\u001b[0m     output_lang \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_lang\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'translator_model_fra_eng2.pth'"
     ]
    }
   ],
   "source": [
    "name = 'translator_model_fra_eng2.pth'\n",
    "loaded_translator = Translator.load(name)\n",
    "transformer = loaded_translator.model\n",
    "input_lang = loaded_translator.input_lang\n",
    "output_lang = loaded_translator.output_lang\n",
    "CONFIG = loaded_translator.config\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PADDING_token)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "min_loss = float(\"+inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dd46b7a-481e-49c7-8766-8dc66de29bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████████████████| 5608/5608 [46:22<00:00,  2.02batch/s, loss=2.19, mean loss=2.09]\n",
      "Epoch 2/10: 100%|████████████████████████████████████| 5608/5608 [47:41<00:00,  1.96batch/s, loss=1.56, mean loss=1.67]\n",
      "Epoch 3/10: 100%|████████████████████████████████████| 5608/5608 [48:55<00:00,  1.91batch/s, loss=1.37, mean loss=1.47]\n",
      "Epoch 4/10: 100%|███████████████████████████████████| 5608/5608 [49:43<00:00,  1.88batch/s, loss=0.895, mean loss=1.34]\n",
      "Epoch 5/10: 100%|████████████████████████████████████| 5608/5608 [49:32<00:00,  1.89batch/s, loss=1.12, mean loss=1.25]\n",
      "Epoch 6/10: 100%|████████████████████████████████████| 5608/5608 [49:28<00:00,  1.89batch/s, loss=1.66, mean loss=1.18]\n",
      "Epoch 7/10: 100%|████████████████████████████████████| 5608/5608 [49:31<00:00,  1.89batch/s, loss=1.02, mean loss=1.14]\n",
      "Epoch 8/10: 100%|████████████████████████████████████| 5608/5608 [49:31<00:00,  1.89batch/s, loss=1.27, mean loss=1.11]\n",
      "Epoch 9/10: 100%|████████████████████████████████████| 5608/5608 [49:03<00:00,  1.91batch/s, loss=0.96, mean loss=1.07]\n",
      "Epoch 10/10: 100%|██████████████████████████████████| 5608/5608 [49:08<00:00,  1.90batch/s, loss=0.804, mean loss=1.05]\n"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "\n",
    "n_epochs = 10\n",
    "min_loss = float(\"+inf\")\n",
    "name = 'translator_model_fra_eng2.pth'\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    losses = 0\n",
    "    with tqdm(total=len(train_dataloader), desc=f'Epoch {epoch}/{n_epochs}', unit='batch') as pbar:\n",
    "        for batch_idx, (src, tgt) in enumerate(train_dataloader):\n",
    "            tgt_input = tgt[:, :-1]\n",
    "\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "            logits = transformer(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            tgt_out = tgt[:,1:]\n",
    "            loss = loss_fn(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "            losses += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Mise à jour de la barre de progression\n",
    "            pbar.set_postfix({'loss': loss.item(), 'mean loss' : losses/(batch_idx+1)})\n",
    "            pbar.update(1)\n",
    "        if min_loss > losses:\n",
    "            min_loss = losses\n",
    "            translator = Translator(transformer, input_lang, output_lang,CONFIG)\n",
    "            translator.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "929bfb04-4bcc-467b-be4e-256c45f5d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(transformer, input_lang, output_lang,CONFIG)\n",
    "translator.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bdb9862-6b18-4f83-b4e9-4e976ed5bf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: [START] is the world green but blue ? [END]\n"
     ]
    }
   ],
   "source": [
    "loaded_translator = Translator.load(name)\n",
    "src_sentence = \"Le monde est vert. mais est t'il bleu ?\"\n",
    "translation = loaded_translator.evaluate(src_sentence)\n",
    "print(\"Translation:\", translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e04fe62-3e6b-48ef-a57a-d103c274e203",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
